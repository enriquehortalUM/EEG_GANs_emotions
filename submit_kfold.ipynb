{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "submit  kfold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_7LlVcNcz45",
        "outputId": "612096fa-bc43-4198-ab66-16a964d89c83"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htBNdHQuavJ4"
      },
      "source": [
        "import numpy as np\n",
        "import pickle as pickle\n",
        "import pandas as pd\n",
        "from scipy.stats import skew,kurtosis\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold,RepeatedKFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.metrics import classification_report,confusion_matrix,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate,cross_val_score\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "# import autosklearn.classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZZPaIL8a_Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578dec52-360d-4a8a-df5d-0081da8b4b87"
      },
      "source": [
        "A = np.load('/content/drive/MyDrive/Thesis data/A.npy') # File with all(40) channel data\n",
        "B = np.load('/content/drive/MyDrive/Thesis data/B.npy') #File with only data from left hemisphere \n",
        "A_norm = np.load('/content/drive/MyDrive/Thesis data/Anorm.npy') # normalised 40 channel data\n",
        "B_norm = np.load('/content/drive/MyDrive/Thesis data/Anorm.npy') # normalised 7 channel data\n",
        "print(\"A.shape =\",A.shape)\n",
        "print(\"B.shape =\",B.shape)\n",
        "#Load the labels now    \n",
        "valence = np.genfromtxt('/content/drive/MyDrive/Thesis data/label_class_0.dat', delimiter=' ')\n",
        "arousal = np.genfromtxt('/content/drive/MyDrive/Thesis data/label_class_1.dat', delimiter=' ')\n",
        "dominance = np.genfromtxt('/content/drive/MyDrive/Thesis data/label_class_2.dat', delimiter=' ')\n",
        "liking = np.genfromtxt('/content/drive/MyDrive/Thesis data/label_class_3.dat', delimiter=' ')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A.shape = (51200, 99)\n",
            "B.shape = (8960, 99)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "villuL2oopGp"
      },
      "source": [
        "## Augmenting data below\r\n",
        "Start with the labels<br>\r\n",
        "For example va2 means valence augmented twice<br>\r\n",
        "ar3 means arousal augmented thrice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qh8HmEYjoM0R"
      },
      "source": [
        "###################################\r\n",
        "# Augmenting the labels \r\n",
        "# 2x\r\n",
        "va2 = np.hstack((valence,valence))\r\n",
        "ar2 = np.hstack((arousal,arousal))\r\n",
        "do2 = np.hstack((dominance,dominance))\r\n",
        "li2 = np.hstack((liking,liking))\r\n",
        "\r\n",
        "\r\n",
        "# 3x\r\n",
        "va3 = np.hstack((valence,valence,valence))\r\n",
        "ar3 = np.hstack((arousal,arousal,arousal))\r\n",
        "do3 = np.hstack((dominance,dominance,dominance))\r\n",
        "li3 = np.hstack((liking,liking,liking))\r\n",
        "\r\n",
        "# 4x\r\n",
        "va4 = np.hstack((valence,valence,valence,valence))\r\n",
        "ar4 = np.hstack((arousal,arousal,arousal,arousal))\r\n",
        "do4 = np.hstack((dominance,dominance,dominance,dominance))\r\n",
        "li5 = np.hstack((liking,liking,liking,liking))\r\n",
        "\r\n",
        "\r\n",
        "# 5x\r\n",
        "va5 = np.hstack((valence,valence,valence,valence,valence))\r\n",
        "ar5 = np.hstack((arousal,arousal,arousal,arousal,arousal))\r\n",
        "do5 = np.hstack((dominance,dominance,dominance,dominance,dominance))\r\n",
        "li5 = np.hstack((liking,liking,liking,liking,liking))\r\n",
        "\r\n",
        "# 10x\r\n",
        "va10 = np.hstack((valence,valence,valence,valence,valence,valence,valence,valence,valence,valence))\r\n",
        "ar10 = np.hstack((arousal,arousal,arousal,arousal,arousal,arousal,arousal,arousal,arousal,arousal))\r\n",
        "do10 = np.hstack((dominance,dominance,dominance,dominance,dominance,dominance,dominance,dominance,dominance,dominance))\r\n",
        "li10 = np.hstack((liking,liking,liking,liking,liking,liking,liking,liking,liking,liking))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXhED7hUq0tR"
      },
      "source": [
        "## Get some generated data points<br>\r\n",
        "Get the data points with generator and discriminator close to zero and least as possible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJPDRgZqf8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1322d3-8375-4d37-8429-14821e6bd695"
      },
      "source": [
        "g1 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep78.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g2 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep80.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g3 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep86.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g4 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep88.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g5 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep90.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g6 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep92.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g7 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep93.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g8 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep94.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g9 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep95.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "g10 =np.load('/content/drive/MyDrive/Thesis data/Generated data/Generated_ep100.npy') # generated data with all(40) channel data\r\n",
        "\r\n",
        "\r\n",
        "g1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 40, 99)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJq9WJhs5Qm"
      },
      "source": [
        "## Augment the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4adTQyWsWQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7cbe52b-4b72-4cf1-94f5-78430c122a26"
      },
      "source": [
        "###################################\r\n",
        "# Augmenting the data \r\n",
        "print(\"Augmenting data............\")\r\n",
        "\r\n",
        "# 2x\r\n",
        "data2 = np.concatenate([g7, A_norm], 0) \r\n",
        "print(data2.shape)\r\n",
        "\r\n",
        "# 3x\r\n",
        "data3 = np.concatenate([g7,g1, A_norm], 0)\r\n",
        "print(data3.shape)\r\n",
        "\r\n",
        "# 4x\r\n",
        "data4 = np.concatenate([g7,g1,g2, A_norm], 0)\r\n",
        "print(data4.shape)\r\n",
        "\r\n",
        "\r\n",
        "# 5x\r\n",
        "data5 = np.concatenate([g7,g1,g2,g3, A_norm], 0)\r\n",
        "print(data5.shape)\r\n",
        "\r\n",
        "# 10x\r\n",
        "data10 = np.concatenate([g1,g2,g3,g4,g5,g6,g7,g8,g9, A_norm], 0)\r\n",
        "print(data10.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting data............\n",
            "(2560, 40, 99)\n",
            "(3840, 40, 99)\n",
            "(5120, 40, 99)\n",
            "(6400, 40, 99)\n",
            "(12800, 40, 99)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnMZlId7uY4X"
      },
      "source": [
        "# Some metrics to be displayed\r\n",
        "conf_matrix = 1\r\n",
        "cls_report = 1\r\n",
        "auc_report = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbgD82jRAqNG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2v8-vXW8Ch"
      },
      "source": [
        "# X = input_data = A_norm.reshape(32*40,40*99) \n",
        "# y = valence\n",
        "\n",
        "# cv_inner = KFold(n_splits=4, shuffle=True, random_state=1)\n",
        "# # define the model\n",
        "# model = KNeighborsClassifier(n_jobs=-1)\n",
        "# #Hyper Parameters Set\n",
        "# params = {'n_neighbors':[1,5,6,7,8,9,10,20],\n",
        "#         'leaf_size':[1,2,3,5],\n",
        "#         'weights':['uniform', 'distance'],\n",
        "#         'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
        "#         'n_jobs':[-1]}\n",
        "# # define search\n",
        "# model1 = GridSearchCV(model, params, scoring='accuracy', n_jobs=1, cv=cv_inner, refit=True)\n",
        "# # configure the cross-validation procedure\n",
        "# cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
        "# # execute the nested cross-validation\n",
        "# scores = cross_val_score(model1, X, y, scoring='accuracy', cv=cv_outer, n_jobs=-1)\n",
        "# # report performance\n",
        "# print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbApFrUYW0Cc"
      },
      "source": [
        "## K fold based "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2ehF4Q9cbkL"
      },
      "source": [
        "### Actual data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvYRRrfRdHEK"
      },
      "source": [
        "X = input_data = A_norm.reshape(32*40,40*99) \n",
        "conf_matrix = 0\n",
        "cls_report = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpPlIvXG6vwP",
        "outputId": "5c1affd5-6e5e-4d06-e633-76d185a712f7"
      },
      "source": [
        "# This is the main K fold block \r\n",
        "y = valence\r\n",
        "# Split the data into training/testing sets\r\n",
        "acc_per_fold = []\r\n",
        "fold_no = 1\r\n",
        "kval = 20\r\n",
        "dispresults = 0\r\n",
        "nsplit = 32\r\n",
        "shuffle = False\r\n",
        "dispfoldres = 0\r\n",
        "print()\r\n",
        "print(\"################# Valence #################\")\r\n",
        "kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\r\n",
        "for train, test in kfold.split(X, y):\r\n",
        "  # print(X[train].shape, X[test].shape)\r\n",
        "  X_train = X[train]\r\n",
        "  y_train = y[train]\r\n",
        "  X_test = X[test]\r\n",
        "  y_test = y[test]\r\n",
        "\r\n",
        "\r\n",
        "  # KNN\r\n",
        "  clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \r\n",
        "  clf.fit(X_train, y_train)\r\n",
        "  y_predict = clf.predict(X_test)\r\n",
        "  acc = accuracy_score(y_test, y_predict)*100\r\n",
        "  acc = round(acc, 4)\r\n",
        "  if dispresults:\r\n",
        "    print(\"Accuracy score for fold\",fold_no)\r\n",
        "    print(acc)\r\n",
        "    print('\\n')\r\n",
        "  acc_per_fold.append(acc)\r\n",
        "  if conf_matrix:\r\n",
        "      print(confusion_matrix(y_test, y_predict))\r\n",
        "  if cls_report:\r\n",
        "      print(classification_report(y_test, y_predict))\r\n",
        "  \r\n",
        "  fold_no = fold_no + 1\r\n",
        "if dispfoldres:  \r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print('Score per fold')\r\n",
        "  for i in range(0, len(acc_per_fold)):\r\n",
        "      print('------------------------------------------------------------------------')\r\n",
        "      print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "print('------------------------------------------------------------------------')\r\n",
        "\r\n",
        "\r\n",
        "  # ###############################################################################\r\n",
        "y = arousal\r\n",
        "# Split the data into training/testing sets\r\n",
        "acc_per_fold = []\r\n",
        "fold_no = 1\r\n",
        "print(\"################# Arousal #################\")\r\n",
        "kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\r\n",
        "for train, test in kfold.split(X, y):\r\n",
        "  # print(X[train].shape, X[test].shape)\r\n",
        "  X_train = X[train]\r\n",
        "  y_train = y[train]\r\n",
        "  X_test = X[test]\r\n",
        "  y_test = y[test]\r\n",
        "  \r\n",
        "    \r\n",
        "  # KNN\r\n",
        "  clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # KNeighborsClassifier(n_neighbors=1) \r\n",
        "  clf.fit(X_train, y_train)\r\n",
        "  y_predict = clf.predict(X_test)\r\n",
        "  acc = accuracy_score(y_test, y_predict)*100\r\n",
        "  acc = round(acc, 4)\r\n",
        "  if dispresults:\r\n",
        "    print(\"Accuracy score for fold\",fold_no)\r\n",
        "    print(acc)\r\n",
        "    print('\\n')\r\n",
        "  acc_per_fold.append(acc)\r\n",
        "  if conf_matrix:\r\n",
        "      print(confusion_matrix(y_test, y_predict))\r\n",
        "  if cls_report:\r\n",
        "      print(classification_report(y_test, y_predict))\r\n",
        "  \r\n",
        "  fold_no = fold_no + 1\r\n",
        "\r\n",
        "if dispfoldres:  \r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print('Score per fold')\r\n",
        "  for i in range(0, len(acc_per_fold)):\r\n",
        "      print('------------------------------------------------------------------------')\r\n",
        "      print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "print('------------------------------------------------------------------------')\r\n",
        "\r\n",
        "  # ###############################################################################\r\n",
        "y = dominance\r\n",
        "# Split the data into training/testing sets\r\n",
        "acc_per_fold = []\r\n",
        "fold_no = 1\r\n",
        "print(\"################# Dominance #################\")\r\n",
        "kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\r\n",
        "for train, test in kfold.split(X, y):\r\n",
        "  # print(X[train].shape, X[test].shape)\r\n",
        "  X_train = X[train]\r\n",
        "  y_train = y[train]\r\n",
        "  X_test = X[test]\r\n",
        "  y_test = y[test]\r\n",
        "\r\n",
        "    \r\n",
        "  # KNN\r\n",
        "  clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \r\n",
        "  clf.fit(X_train, y_train)\r\n",
        "  y_predict = clf.predict(X_test)\r\n",
        "  acc = accuracy_score(y_test, y_predict)*100\r\n",
        "  acc = round(acc, 4)\r\n",
        "  if dispresults:\r\n",
        "    print(\"Accuracy score for fold\",fold_no)\r\n",
        "    print(acc)\r\n",
        "    print('\\n')\r\n",
        "  acc_per_fold.append(acc)\r\n",
        "  if conf_matrix:\r\n",
        "      print(confusion_matrix(y_test, y_predict))\r\n",
        "  if cls_report:\r\n",
        "      print(classification_report(y_test, y_predict))\r\n",
        "  \r\n",
        "  fold_no = fold_no + 1\r\n",
        "\r\n",
        "if dispfoldres:  \r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print('Score per fold')\r\n",
        "  for i in range(0, len(acc_per_fold)):\r\n",
        "      print('------------------------------------------------------------------------')\r\n",
        "      print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "print('------------------------------------------------------------------------')\r\n",
        "\r\n",
        "  # ###############################################################################\r\n",
        "\r\n",
        "y = liking\r\n",
        "# Split the data into training/testing sets\r\n",
        "acc_per_fold = []\r\n",
        "fold_no = 1\r\n",
        "print(\"#################Liking#################\")\r\n",
        "kfold = KFold(n_splits=nsplit,shuffle=shuffle) # 4,8,32\r\n",
        "for train, test in kfold.split(X, y):\r\n",
        "  # print(X[train].shape, X[test].shape)\r\n",
        "  X_train = X[train]\r\n",
        "  y_train = y[train]\r\n",
        "  X_test = X[test]\r\n",
        "  y_test = y[test]\r\n",
        "\r\n",
        "    \r\n",
        "  # KNN\r\n",
        "  clf = KNeighborsClassifier(n_neighbors=kval) #RandomForestClassifier(n_jobs=-1,random_state=123)# DecisionTreeClassifier(random_state=123) # clf = KNeighborsClassifier(n_neighbors=1) \r\n",
        "  clf.fit(X_train, y_train)\r\n",
        "  y_predict = clf.predict(X_test)\r\n",
        "  acc = accuracy_score(y_test, y_predict)*100\r\n",
        "  acc = round(acc, 4)\r\n",
        "  if dispresults:\r\n",
        "    print(\"Accuracy score for fold\",fold_no)\r\n",
        "    print(acc)\r\n",
        "    print('\\n')\r\n",
        "  acc_per_fold.append(acc)\r\n",
        "  \r\n",
        "  if conf_matrix:\r\n",
        "      print(confusion_matrix(y_test, y_predict))\r\n",
        "  if cls_report:\r\n",
        "      print(classification_report(y_test, y_predict))\r\n",
        "  \r\n",
        "  fold_no = fold_no + 1\r\n",
        "if dispfoldres:  \r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print('Score per fold')\r\n",
        "  for i in range(0, len(acc_per_fold)):\r\n",
        "      print('------------------------------------------------------------------------')\r\n",
        "      print(f'> Fold {i+1} Accuracy: {acc_per_fold[i]}%')\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "print(\"For K value -\",kval, \"and nsplits\",nsplit,\"shuffle -\",shuffle)\r\n",
        "print('Average scores for all folds:')\r\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\r\n",
        "print('------------------------------------------------------------------------')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "################# Valence #################\n",
            "For K value - 20 and nsplits 32 shuffle - False\n",
            "Average scores for all folds:\n",
            "> Accuracy: 52.890625 (+- 7.858846900746635)\n",
            "------------------------------------------------------------------------\n",
            "################# Arousal #################\n",
            "For K value - 20 and nsplits 32 shuffle - False\n",
            "Average scores for all folds:\n",
            "> Accuracy: 51.40625 (+- 12.746591149695671)\n",
            "------------------------------------------------------------------------\n",
            "################# Dominance #################\n",
            "For K value - 20 and nsplits 32 shuffle - False\n",
            "Average scores for all folds:\n",
            "> Accuracy: 55.9375 (+- 10.28405166994021)\n",
            "------------------------------------------------------------------------\n",
            "#################Liking#################\n",
            "For K value - 20 and nsplits 32 shuffle - False\n",
            "Average scores for all folds:\n",
            "> Accuracy: 62.265625 (+- 10.238548767250904)\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cNkLUjvjXqg"
      },
      "source": [
        "Running different trials, best results obtained so far was <br>\r\n",
        "55.156%  57.031%  59.609%  66.796% for valence arousal dominance and liking labels\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82g-TvzHqUsT"
      },
      "source": [
        "Similar experiments were done for generated data and also the data from only left hemisphere. Results are shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4v_0VpFcle1"
      },
      "source": [
        "### Generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCV3OzCe7lbc"
      },
      "source": [
        "# Results for generated data \r\n",
        "# Accuracy of  Valence 52.37723281607032 (+- 8.160543056012836)\r\n",
        "# Accuracy of  Arousal 52.82366136088967 (+- 12.77826730998265)\r\n",
        "# Accuracy of  Dominance 50.63616163097322 (+- 11.841633770384124)\r\n",
        "# Accuracy of  Liking 56.752233393490314 (+- 14.056293990827761)\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UhfcdOeU3KG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHJSE-6Np2ez"
      },
      "source": [
        "### 7 channel data from left hemisphere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7so2VM8p2fJ"
      },
      "source": [
        "# Accuracy of  Valence 52.37723281607032 (+- 8.160543056012836)\r\n",
        "# Accuracy of  Arousal 52.82366136088967 (+- 12.77826730998265)\r\n",
        "# Accuracy of  Dominance 50.63616163097322 (+- 11.841633770384124)\r\n",
        "# Accuracy of  Liking 56.752233393490314 (+- 14.056293990827761)\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zYcZOPp2fL"
      },
      "source": [
        ""
      ]
    }
  ]
}